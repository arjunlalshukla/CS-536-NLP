{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 5 * 2 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-953e01372b97>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-953e01372b97>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1 +\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1 +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import matplotlib\n",
    "import random\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance('monstrous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 79 matches:\n",
      ", however , and , as a mark of his affection for the three girls , he left them\n",
      "t . It was very well known that no affection was ever supposed to exist between\n",
      "deration of politeness or maternal affection on the side of the former , the tw\n",
      "d the suspicion -- the hope of his affection for me may warrant , without impru\n",
      "hich forbade the indulgence of his affection . She knew that his mother neither\n",
      "rd she gave one with still greater affection . Though her late conversation wit\n",
      " can never hope to feel or inspire affection again , and if her home be uncomfo\n",
      "m of the sense , elegance , mutual affection , and domestic comfort of the fami\n",
      ", and which recommended him to her affection beyond every thing else . His soci\n",
      "ween the parties might forward the affection of Mr . Willoughby , an equally st\n",
      " the most pointed assurance of her affection . Elinor could not be surprised at\n",
      "he natural consequence of a strong affection in a young and ardent mind . This \n",
      " opinion . But by an appeal to her affection for her mother , by representing t\n",
      " every alteration of a place which affection had established as perfect with hi\n",
      "e will always have one claim of my affection , which no other can possibly shar\n",
      "f the evening declared at once his affection and happiness . \" Shall we see you\n",
      "ause he took leave of us with less affection than his usual behaviour has shewn\n",
      "ness .\" \" I want no proof of their affection ,\" said Elinor ; \" but of their en\n",
      "onths , without telling her of his affection ;-- that they should part without \n",
      "ould be the natural result of your affection for her . She used to be all unres\n",
      "distinguished Elinor by no mark of affection . Marianne saw and listened with i\n",
      "th no inclination for expense , no affection for strangers , no profession , an\n",
      "till distinguished her by the same affection which once she had felt no doubt o\n",
      "al of her confidence in Edward ' s affection , to the remembrance of every mark\n",
      " was made ? Had he never owned his affection to yourself ?\" \" Oh , no ; but if \n"
     ]
    }
   ],
   "source": [
    "text2.concordance('affection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 38 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "text3.concordance('lived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar('monstrous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar('monstrous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts(['monstrous', 'very'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man ship fellow whaleman pequod body brain he world whale fish more\n",
      "devil leviathan one lord monster boat indian king\n"
     ]
    }
   ],
   "source": [
    "text1.similar('son')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man ship fellow whaleman pequod body brain he world whale fish more\n",
      "devil leviathan one lord monster boat indian king\n"
     ]
    }
   ],
   "source": [
    "text1.similar('mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother sister mind own brother and house that time family heart wife\n",
      "feelings daughter happiness carriage side visit name friend\n"
     ]
    }
   ],
   "source": [
    "text2.similar('son')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sister brother heart own mind family sisters feelings house son wife\n",
      "life marriage husband eyes and attention conduct daughter head\n"
     ]
    }
   ],
   "source": [
    "text2.similar('mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No common contexts were found\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts(['son', 'mother'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his_but his_and his_s his_was his_in her_in her_and her_to her_she\n",
      "her_you her_his\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts(['son', 'mother'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot(['citizens','democracy','freedom','duties','America'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate() missing 1 required positional argument: 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-463eb7c367ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: generate() missing 1 required positional argument: 'words'"
     ]
    }
   ],
   "source": [
    "text3.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))/len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text4.count('a') / len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.count('lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5640968673628082"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text5.count('lol') / len(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text))/len(text)\n",
    "def percentage(count, total):\n",
    "    return 100*count/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Dashwood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settled',\n",
       " 'in',\n",
       " 'Sussex',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'God',\n",
       " 'created',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Python', 'and', 'the', 'Holy', 'Grail']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Monty', 'Python'] + ['and', 'the', 'Holy', 'Grail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow',\n",
       " '-',\n",
       " 'Citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Senate',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'House',\n",
       " 'of',\n",
       " 'Representatives',\n",
       " ':',\n",
       " 'Call',\n",
       " 'me',\n",
       " 'Ishmael',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 + sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Some']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.append('Some')\n",
    "sent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awaken'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U86',\n",
       " 'thats',\n",
       " 'why',\n",
       " 'something',\n",
       " 'like',\n",
       " 'gamefly',\n",
       " 'is',\n",
       " 'so',\n",
       " 'good',\n",
       " 'because',\n",
       " 'you',\n",
       " 'can',\n",
       " 'actually',\n",
       " 'play',\n",
       " 'a',\n",
       " 'full',\n",
       " 'game',\n",
       " 'without',\n",
       " 'buying',\n",
       " 'it']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5[16715:16735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'\",\n",
       " 're',\n",
       " 'an',\n",
       " 'anarcho',\n",
       " '-',\n",
       " 'syndicalist',\n",
       " 'commune',\n",
       " '.',\n",
       " 'We',\n",
       " 'take',\n",
       " 'it',\n",
       " 'in',\n",
       " 'turns',\n",
       " 'to',\n",
       " 'act',\n",
       " 'as',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'executive',\n",
       " 'officer',\n",
       " 'for',\n",
       " 'the',\n",
       " 'week']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text6[1600:1625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word1'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['word1', 'word2', 'word3', 'word4', 'word5', 'word6', 'word7', 'word8', 'word9', 'word10']\n",
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word10'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-baa8b4ccd19d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word6', 'word7', 'word8']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word6'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word7'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word8'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word1', 'word2', 'word3']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['among',\n",
       " 'the',\n",
       " 'merits',\n",
       " 'and',\n",
       " 'the',\n",
       " 'happiness',\n",
       " 'of',\n",
       " 'Elinor',\n",
       " 'and',\n",
       " 'Marianne',\n",
       " ',',\n",
       " 'let',\n",
       " 'it',\n",
       " 'not',\n",
       " 'be',\n",
       " 'ranked',\n",
       " 'as',\n",
       " 'the',\n",
       " 'least',\n",
       " 'considerable',\n",
       " ',',\n",
       " 'that',\n",
       " 'though',\n",
       " 'sisters',\n",
       " ',',\n",
       " 'and',\n",
       " 'living',\n",
       " 'almost',\n",
       " 'within',\n",
       " 'sight',\n",
       " 'of',\n",
       " 'each',\n",
       " 'other',\n",
       " ',',\n",
       " 'they',\n",
       " 'could',\n",
       " 'live',\n",
       " 'without',\n",
       " 'disagreement',\n",
       " 'between',\n",
       " 'themselves',\n",
       " ',',\n",
       " 'or',\n",
       " 'producing',\n",
       " 'coolness',\n",
       " 'between',\n",
       " 'their',\n",
       " 'husbands',\n",
       " '.',\n",
       " 'THE',\n",
       " 'END']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[141525:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0] = 'First'\n",
    "sent[9] = 'Last'\n",
    "len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First', 'Second', 'Third', 'Last']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[1:9] = ['Second', 'Third']\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9d73df3f8677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bold', 'Sir', 'Robin']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    "my_sent = ['Bravely', 'bold', 'Sir', 'Robin', ',', 'rode', 'forth', 'from', 'Camelot', '.']\n",
    "noun_phrase = my_sent[1:4]\n",
    "noun_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robin', 'Sir', 'bold']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0rds = sorted(noun_phrase)\n",
    "w0rds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-57-673e7f915d89>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-673e7f915d89>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    not = 'Camelot'\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "not = 'Camelot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(text1)\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Monty'\n",
    "name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mont'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MontyMonty'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty!'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name + '!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['Monty', 'Python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Python']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty Python'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said', 'than']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', 'more', 'is', 'said', 'than', 'done']\n",
    "tokens = set(saying)\n",
    "tokens = sorted(tokens)\n",
    "tokens[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1 = FreqDist(text1)\n",
    "print(fdist1)\n",
    "fdist1.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6833 samples and 141576 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 9397),\n",
       " ('to', 4063),\n",
       " ('.', 3975),\n",
       " ('the', 3861),\n",
       " ('of', 3565),\n",
       " ('and', 3350),\n",
       " ('her', 2436),\n",
       " ('a', 2043),\n",
       " ('I', 2004),\n",
       " ('in', 1904),\n",
       " ('was', 1846),\n",
       " ('it', 1568),\n",
       " ('\"', 1506),\n",
       " (';', 1419),\n",
       " ('she', 1333),\n",
       " ('be', 1305),\n",
       " ('that', 1297),\n",
       " ('for', 1234),\n",
       " ('not', 1212),\n",
       " ('as', 1179),\n",
       " ('you', 1037),\n",
       " ('with', 971),\n",
       " ('had', 969),\n",
       " ('his', 941),\n",
       " ('he', 895),\n",
       " (\"'\", 883),\n",
       " ('have', 807),\n",
       " ('at', 806),\n",
       " ('by', 737),\n",
       " ('is', 728),\n",
       " ('.\"', 721),\n",
       " ('s', 700),\n",
       " ('Elinor', 684),\n",
       " ('on', 676),\n",
       " ('all', 642),\n",
       " ('him', 633),\n",
       " ('so', 617),\n",
       " ('but', 597),\n",
       " ('which', 592),\n",
       " ('could', 568),\n",
       " ('Marianne', 566),\n",
       " ('my', 551),\n",
       " ('Mrs', 530),\n",
       " ('from', 527),\n",
       " ('would', 507),\n",
       " ('very', 492),\n",
       " ('no', 488),\n",
       " ('their', 463),\n",
       " ('them', 462),\n",
       " ('--', 461)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2 = FreqDist(text2)\n",
    "print(fdist2)\n",
    "fdist2.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2436"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2['her']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIRCUMNAVIGATION',\n",
       " 'Physiognomically',\n",
       " 'apprehensiveness',\n",
       " 'cannibalistically',\n",
       " 'characteristically',\n",
       " 'circumnavigating',\n",
       " 'circumnavigation',\n",
       " 'circumnavigations',\n",
       " 'comprehensiveness',\n",
       " 'hermaphroditical',\n",
       " 'indiscriminately',\n",
       " 'indispensableness',\n",
       " 'irresistibleness',\n",
       " 'physiognomically',\n",
       " 'preternaturalness',\n",
       " 'responsibilities',\n",
       " 'simultaneousness',\n",
       " 'subterraneousness',\n",
       " 'supernaturalness',\n",
       " 'superstitiousness',\n",
       " 'uncomfortableness',\n",
       " 'uncompromisedness',\n",
       " 'undiscriminating',\n",
       " 'uninterpenetratingly']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = set(text1)\n",
    "long_words = [w for w in V if len(w) > 15]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uninterpenetratingly']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(text1)\n",
    "long_words = [word for word in vocab if len(word) > 18]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#14-19teens',\n",
       " '#talkcity_adults',\n",
       " '((((((((((',\n",
       " '........',\n",
       " 'Question',\n",
       " 'actually',\n",
       " 'anything',\n",
       " 'computer',\n",
       " 'cute.-ass',\n",
       " 'everyone',\n",
       " 'football',\n",
       " 'innocent',\n",
       " 'listening',\n",
       " 'remember',\n",
       " 'seriously',\n",
       " 'something',\n",
       " 'together',\n",
       " 'tomorrow',\n",
       " 'watching']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist5 = FreqDist(text5)\n",
    "sorted(w for w in set(text5) if len(w) > 7 and fdist5[w] > 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('more', 'is'), ('is', 'said'), ('said', 'than'), ('than', 'done')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(['more', 'is', 'said', 'than', 'done']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would like; medium build; social drinker; quiet nights; non smoker;\n",
      "long term; age open; Would like; easy going; financially secure; fun\n",
      "times; similar interests; Age open; weekends away; poss rship; well\n",
      "presented; never married; single mum; permanent relationship; slim\n",
      "build\n"
     ]
    }
   ],
   "source": [
    "text8.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19 samples and 260819 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({3: 50223, 1: 47933, 4: 42345, 2: 38513, 5: 26597, 6: 17111, 7: 14399, 8: 9966, 9: 6428, 10: 3528, ...})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(len(w) for w  in text1)\n",
    "print(fdist)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 50223),\n",
       " (1, 47933),\n",
       " (4, 42345),\n",
       " (2, 38513),\n",
       " (5, 26597),\n",
       " (6, 17111),\n",
       " (7, 14399),\n",
       " (8, 9966),\n",
       " (9, 6428),\n",
       " (10, 3528),\n",
       " (11, 1873),\n",
       " (12, 1053),\n",
       " (13, 567),\n",
       " (14, 177),\n",
       " (15, 70),\n",
       " (16, 22),\n",
       " (17, 12),\n",
       " (18, 1),\n",
       " (20, 1)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50223"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19255882431878046"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.freq(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '61', 'old', ',', 'the', 'as', 'a', '29', '.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '61', 'old', ',', 'will', 'join', 'the', 'as', 'a', 'Nov.', '29', '.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) <= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will', 'join', 'Nov.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comfortableness',\n",
       " 'honourableness',\n",
       " 'immutableness',\n",
       " 'indispensableness',\n",
       " 'indomitableness',\n",
       " 'intolerableness',\n",
       " 'palpableness',\n",
       " 'reasonableness',\n",
       " 'uncomfortableness']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text1) if w.endswith('ableness'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sovereignty', 'sovereignties', 'sovereignty']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(term for term in set(text4) if 'gnt' in term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Aaaaaaaaah',\n",
       " 'Aaaaaaaah',\n",
       " 'Aaaaaah',\n",
       " 'Aaaah',\n",
       " 'Aaaaugh',\n",
       " 'Aaagh',\n",
       " 'Aaah',\n",
       " 'Aaauggh',\n",
       " 'Aaaugh',\n",
       " 'Aaauugh',\n",
       " 'Aagh',\n",
       " 'Aah',\n",
       " 'Aauuggghhh',\n",
       " 'Aauuugh',\n",
       " 'Aauuuuugh',\n",
       " 'Aauuuves',\n",
       " 'Action',\n",
       " 'Actually',\n",
       " 'African',\n",
       " 'Ages',\n",
       " 'Aggh',\n",
       " 'Agh',\n",
       " 'Ah',\n",
       " 'Ahh',\n",
       " 'Alice',\n",
       " 'All',\n",
       " 'Allo',\n",
       " 'Almighty',\n",
       " 'Alright',\n",
       " 'Am',\n",
       " 'Amen',\n",
       " 'An',\n",
       " 'Anarcho',\n",
       " 'And',\n",
       " 'Angnor',\n",
       " 'Anthrax',\n",
       " 'Antioch',\n",
       " 'Anybody',\n",
       " 'Anyway',\n",
       " 'Apples',\n",
       " 'Aramaic',\n",
       " 'Are',\n",
       " 'Arimathea',\n",
       " 'Armaments',\n",
       " 'Arthur',\n",
       " 'As',\n",
       " 'Ask',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Attila',\n",
       " 'Augh',\n",
       " 'Autumn',\n",
       " 'Auuuuuuuugh',\n",
       " 'Away',\n",
       " 'Ay',\n",
       " 'Ayy',\n",
       " 'B',\n",
       " 'Back',\n",
       " 'Bad',\n",
       " 'Badon',\n",
       " 'Battle',\n",
       " 'Be',\n",
       " 'Beast',\n",
       " 'Bedevere',\n",
       " 'Bedwere',\n",
       " 'Behold',\n",
       " 'Between',\n",
       " 'Beyond',\n",
       " 'Black',\n",
       " 'Bloody',\n",
       " 'Blue',\n",
       " 'Bon',\n",
       " 'Bones',\n",
       " 'Book',\n",
       " 'Bors',\n",
       " 'Brave',\n",
       " 'Bravely',\n",
       " 'Bravest',\n",
       " 'Bread',\n",
       " 'Bridge',\n",
       " 'Bring',\n",
       " 'Bristol',\n",
       " 'Britain',\n",
       " 'Britons',\n",
       " 'Brother',\n",
       " 'Build',\n",
       " 'Burn',\n",
       " 'But',\n",
       " 'By',\n",
       " 'C',\n",
       " 'Caerbannog',\n",
       " 'Camaaaaaargue',\n",
       " 'Camelot',\n",
       " 'Castle',\n",
       " 'Chapter',\n",
       " 'Charge',\n",
       " 'Chaste',\n",
       " 'Cherries',\n",
       " 'Chicken',\n",
       " 'Chickennn',\n",
       " 'Chop',\n",
       " 'Christ',\n",
       " 'Churches',\n",
       " 'Cider',\n",
       " 'Clark',\n",
       " 'Clear',\n",
       " 'Come',\n",
       " 'Concorde',\n",
       " 'Consult',\n",
       " 'Cornwall',\n",
       " 'Could',\n",
       " 'Course',\n",
       " 'Court',\n",
       " 'Crapper',\n",
       " 'Cut',\n",
       " 'Dappy',\n",
       " 'Death',\n",
       " 'Defeat',\n",
       " 'Dennis',\n",
       " 'Did',\n",
       " 'Didn',\n",
       " 'Dingo',\n",
       " 'Dis',\n",
       " 'Divine',\n",
       " 'Do',\n",
       " 'Doctor',\n",
       " 'Does',\n",
       " 'Don',\n",
       " 'Dragon',\n",
       " 'Dramatically',\n",
       " 'Ecky',\n",
       " 'Ector',\n",
       " 'Eee',\n",
       " 'Eh',\n",
       " 'Enchanter',\n",
       " 'England',\n",
       " 'English',\n",
       " 'Erbert',\n",
       " 'Ere',\n",
       " 'Erm',\n",
       " 'Eternal',\n",
       " 'European',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Everything',\n",
       " 'Ewing',\n",
       " 'Exactly',\n",
       " 'Excalibur',\n",
       " 'Excuse',\n",
       " 'Explain',\n",
       " 'Far',\n",
       " 'Farewell',\n",
       " 'Father',\n",
       " 'Fetchez',\n",
       " 'Fiends',\n",
       " 'Fine',\n",
       " 'First',\n",
       " 'Firstly',\n",
       " 'Five',\n",
       " 'Follow',\n",
       " 'For',\n",
       " 'Forgive',\n",
       " 'Forward',\n",
       " 'Found',\n",
       " 'Four',\n",
       " 'France',\n",
       " 'Frank',\n",
       " 'French',\n",
       " 'Gable',\n",
       " 'Galahad',\n",
       " 'Gallahad',\n",
       " 'Gawain',\n",
       " 'Get',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Good',\n",
       " 'Gorge',\n",
       " 'Grail',\n",
       " 'Great',\n",
       " 'Greetings',\n",
       " 'Grenade',\n",
       " 'Guards',\n",
       " 'Guy',\n",
       " 'Ha',\n",
       " 'Hah',\n",
       " 'Hallo',\n",
       " 'Halt',\n",
       " 'Hand',\n",
       " 'Hang',\n",
       " 'Have',\n",
       " 'Haw',\n",
       " 'He',\n",
       " 'Hee',\n",
       " 'Heee',\n",
       " 'Heh',\n",
       " 'Hello',\n",
       " 'Help',\n",
       " 'Herbert',\n",
       " 'Here',\n",
       " 'Hey',\n",
       " 'Hic',\n",
       " 'Hill',\n",
       " 'Himself',\n",
       " 'His',\n",
       " 'Hiyaah',\n",
       " 'Hiyah',\n",
       " 'Hiyya',\n",
       " 'Hm',\n",
       " 'Hmm',\n",
       " 'Ho',\n",
       " 'Hoa',\n",
       " 'Hold',\n",
       " 'Holy',\n",
       " 'Honestly',\n",
       " 'Hoo',\n",
       " 'Hooray',\n",
       " 'How',\n",
       " 'Huh',\n",
       " 'Hurry',\n",
       " 'Huy',\n",
       " 'Huyah',\n",
       " 'Hya',\n",
       " 'Hyy',\n",
       " 'I',\n",
       " 'Idiom',\n",
       " 'Iesu',\n",
       " 'If',\n",
       " 'Iiiiives',\n",
       " 'Iiiives',\n",
       " 'In',\n",
       " 'Is',\n",
       " 'Isn',\n",
       " 'It',\n",
       " 'Ives',\n",
       " 'Jesus',\n",
       " 'Joseph',\n",
       " 'Just',\n",
       " 'Keep',\n",
       " 'King',\n",
       " 'Knight',\n",
       " 'Knights',\n",
       " 'Lady',\n",
       " 'Lake',\n",
       " 'Lancelot',\n",
       " 'Launcelot',\n",
       " 'Lead',\n",
       " 'Leaving',\n",
       " 'Let',\n",
       " 'Lie',\n",
       " 'Like',\n",
       " 'Listen',\n",
       " 'Loimbard',\n",
       " 'Look',\n",
       " 'Looks',\n",
       " 'Lord',\n",
       " 'Lucky',\n",
       " 'Make',\n",
       " 'Man',\n",
       " 'May',\n",
       " 'Maynard',\n",
       " 'Meanwhile',\n",
       " 'Mercea',\n",
       " 'Message',\n",
       " 'Midget',\n",
       " 'Mind',\n",
       " 'Mine',\n",
       " 'Mmm',\n",
       " 'Monsieur',\n",
       " 'More',\n",
       " 'Morning',\n",
       " 'Most',\n",
       " 'Mother',\n",
       " 'Mud',\n",
       " 'Must',\n",
       " 'My',\n",
       " 'N',\n",
       " 'Nador',\n",
       " 'Nay',\n",
       " 'Neee',\n",
       " 'Never',\n",
       " 'Ni',\n",
       " 'Nine',\n",
       " 'Ninepence',\n",
       " 'No',\n",
       " 'None',\n",
       " 'Not',\n",
       " 'Nothing',\n",
       " 'Now',\n",
       " 'Nu',\n",
       " 'O',\n",
       " 'Of',\n",
       " 'Off',\n",
       " 'Oh',\n",
       " 'Ohh',\n",
       " 'Old',\n",
       " 'Olfin',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'One',\n",
       " 'Ooh',\n",
       " 'Oooh',\n",
       " 'Oooo',\n",
       " 'Oooohoohohooo',\n",
       " 'Oooooooh',\n",
       " 'Open',\n",
       " 'Or',\n",
       " 'Order',\n",
       " 'Other',\n",
       " 'Oui',\n",
       " 'Our',\n",
       " 'Over',\n",
       " 'Ow',\n",
       " 'Packing',\n",
       " 'Patsy',\n",
       " 'Pendragon',\n",
       " 'Peng',\n",
       " 'Perhaps',\n",
       " 'Peril',\n",
       " 'Picture',\n",
       " 'Pie',\n",
       " 'Piglet',\n",
       " 'Pin',\n",
       " 'Please',\n",
       " 'Practice',\n",
       " 'Prepare',\n",
       " 'Prince',\n",
       " 'Princess',\n",
       " 'Providence',\n",
       " 'Psalms',\n",
       " 'Pull',\n",
       " 'Pure',\n",
       " 'Put',\n",
       " 'Quick',\n",
       " 'Quickly',\n",
       " 'Quiet',\n",
       " 'Quite',\n",
       " 'Quoi',\n",
       " 'Rather',\n",
       " 'Really',\n",
       " 'Recently',\n",
       " 'Remove',\n",
       " 'Rheged',\n",
       " 'Ridden',\n",
       " 'Right',\n",
       " 'Riiight',\n",
       " 'Robin',\n",
       " 'Robinson',\n",
       " 'Roger',\n",
       " 'Round',\n",
       " 'Run',\n",
       " 'Running',\n",
       " 'S',\n",
       " 'Said',\n",
       " 'Saint',\n",
       " 'Saxons',\n",
       " 'Say',\n",
       " 'Schools',\n",
       " 'See',\n",
       " 'Seek',\n",
       " 'Shall',\n",
       " 'She',\n",
       " 'Shh',\n",
       " 'Shrubber',\n",
       " 'Shrubberies',\n",
       " 'Shut',\n",
       " 'Silence',\n",
       " 'Silly',\n",
       " 'Since',\n",
       " 'Sir',\n",
       " 'Skip',\n",
       " 'So',\n",
       " 'Sorry',\n",
       " 'Speak',\n",
       " 'Splendid',\n",
       " 'Spring',\n",
       " 'Stand',\n",
       " 'Stay',\n",
       " 'Steady',\n",
       " 'Stop',\n",
       " 'Summer',\n",
       " 'Supposing',\n",
       " 'Supreme',\n",
       " 'Surely',\n",
       " 'Swamp',\n",
       " 'Table',\n",
       " 'Tale',\n",
       " 'Tall',\n",
       " 'Tell',\n",
       " 'Thank',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Thee',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Thou',\n",
       " 'Thpppppt',\n",
       " 'Thppppt',\n",
       " 'Thpppt',\n",
       " 'Thppt',\n",
       " 'Three',\n",
       " 'Throw',\n",
       " 'Thsss',\n",
       " 'Thursday',\n",
       " 'Thy',\n",
       " 'Til',\n",
       " 'Tim',\n",
       " 'Tis',\n",
       " 'To',\n",
       " 'Today',\n",
       " 'Together',\n",
       " 'Too',\n",
       " 'Torment',\n",
       " 'Tower',\n",
       " 'True',\n",
       " 'Try',\n",
       " 'Twenty',\n",
       " 'Two',\n",
       " 'U',\n",
       " 'Uh',\n",
       " 'Uhh',\n",
       " 'Ulk',\n",
       " 'Um',\n",
       " 'Umhm',\n",
       " 'Umm',\n",
       " 'Un',\n",
       " 'Unfortunately',\n",
       " 'Until',\n",
       " 'Use',\n",
       " 'Uther',\n",
       " 'Uugh',\n",
       " 'Uuh',\n",
       " 'Very',\n",
       " 'Victory',\n",
       " 'W',\n",
       " 'Waa',\n",
       " 'Wait',\n",
       " 'Walk',\n",
       " 'Wayy',\n",
       " 'We',\n",
       " 'Welcome',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Where',\n",
       " 'Which',\n",
       " 'Who',\n",
       " 'Whoa',\n",
       " 'Why',\n",
       " 'Will',\n",
       " 'Winston',\n",
       " 'Winter',\n",
       " 'With',\n",
       " 'Woa',\n",
       " 'Wood',\n",
       " 'Would',\n",
       " 'Y',\n",
       " 'Yapping',\n",
       " 'Yay',\n",
       " 'Yeaaah',\n",
       " 'Yeaah',\n",
       " 'Yeah',\n",
       " 'Yes',\n",
       " 'You',\n",
       " 'Your',\n",
       " 'Yup',\n",
       " 'Zoot']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(text6) if item.istitle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '61']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock-index',\n",
       " 'index-arbitrage',\n",
       " 'index-fund',\n",
       " 'index-options',\n",
       " 'index-related',\n",
       " 'stock-index']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks for the work 'index' as part of a hyphenated compound\n",
    "sorted(w for w in set(text7) if '-' in w and 'index' in w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abelmizraim',\n",
       " 'Allonbachuth',\n",
       " 'Beerlahairoi',\n",
       " 'Canaanitish',\n",
       " 'Chedorlaomer',\n",
       " 'Girgashites',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Ishmeelites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Kirjatharba',\n",
       " 'Melchizedek',\n",
       " 'Mesopotamia',\n",
       " 'Peradventure',\n",
       " 'Philistines',\n",
       " 'Zaphnathpaaneah']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks for words beginning with capital letter longer than 10 characters\n",
    "sorted(wd for wd in set(text3) if wd.istitle() and len(wd) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', '29', '61', 'Nov.', 'Pierre', 'Vinken']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds every word and is not entirely composed of lower-case letters\n",
    "sorted(w for w in set(sent7) if not w.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ancient',\n",
       " 'ceiling',\n",
       " 'conceit',\n",
       " 'conceited',\n",
       " 'conceive',\n",
       " 'conscience',\n",
       " 'conscientious',\n",
       " 'conscientiously',\n",
       " 'deceitful',\n",
       " 'deceive',\n",
       " 'deceived',\n",
       " 'deceiving',\n",
       " 'deficiencies',\n",
       " 'deficiency',\n",
       " 'deficient',\n",
       " 'delicacies',\n",
       " 'excellencies',\n",
       " 'fancied',\n",
       " 'insufficiency',\n",
       " 'insufficient',\n",
       " 'legacies',\n",
       " 'perceive',\n",
       " 'perceived',\n",
       " 'perceiving',\n",
       " 'prescience',\n",
       " 'prophecies',\n",
       " 'receipt',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'receiving',\n",
       " 'society',\n",
       " 'species',\n",
       " 'sufficient',\n",
       " 'sufficiently',\n",
       " 'undeceive',\n",
       " 'undeceiving']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like it's meant to test the 'i before e' rule\n",
    "sorted(t for t in set(text2) if 'cie' in t or 'cei' in t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cleveland',\n",
       " 'England',\n",
       " 'Finland',\n",
       " 'Holland',\n",
       " 'Inland',\n",
       " 'Island',\n",
       " 'Islands',\n",
       " 'Kurland',\n",
       " 'Maryland',\n",
       " 'Mayland',\n",
       " 'Midland',\n",
       " 'Nederlanden',\n",
       " 'Netherlands',\n",
       " 'Orlando',\n",
       " 'Poland',\n",
       " 'Roland',\n",
       " 'Scotland',\n",
       " 'Switzerland',\n",
       " 'Thailand',\n",
       " 'Wayland',\n",
       " 'Wheeland',\n",
       " 'Zealand']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t for t in set(text7) if 'land' in t and t.istitle())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'MOBY',\n",
       " 'DICK',\n",
       " 'BY',\n",
       " 'HERMAN',\n",
       " 'MELVILLE',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'SUPPLIED',\n",
       " 'BY',\n",
       " 'A',\n",
       " 'LATE',\n",
       " 'CONSUMPTIVE',\n",
       " 'USHER',\n",
       " 'TO',\n",
       " 'A',\n",
       " 'GRAMMAR',\n",
       " 'SCHOOL',\n",
       " ')',\n",
       " 'THE',\n",
       " 'PALE',\n",
       " 'USHER',\n",
       " '--',\n",
       " 'THREADBARE',\n",
       " 'IN',\n",
       " 'COAT',\n",
       " ',',\n",
       " 'HEART',\n",
       " ',',\n",
       " 'BODY',\n",
       " ',',\n",
       " 'AND',\n",
       " 'BRAIN',\n",
       " ';',\n",
       " 'I',\n",
       " 'SEE',\n",
       " 'HIM',\n",
       " 'NOW',\n",
       " '.',\n",
       " 'HE',\n",
       " 'WAS',\n",
       " 'EVER',\n",
       " 'DUSTING',\n",
       " 'HIS',\n",
       " 'OLD',\n",
       " 'LEXICONS',\n",
       " 'AND',\n",
       " 'GRAMMARS',\n",
       " ',',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'QUEER',\n",
       " 'HANDKERCHIEF',\n",
       " ',',\n",
       " 'MOCKINGLY',\n",
       " 'EMBELLISHED',\n",
       " 'WITH',\n",
       " 'ALL',\n",
       " 'THE',\n",
       " 'GAY',\n",
       " 'FLAGS',\n",
       " 'OF',\n",
       " 'ALL',\n",
       " 'THE',\n",
       " 'KNOWN',\n",
       " 'NATIONS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'WORLD',\n",
       " '.',\n",
       " 'HE',\n",
       " 'LOVED',\n",
       " 'TO',\n",
       " 'DUST',\n",
       " 'HIS',\n",
       " 'OLD',\n",
       " 'GRAMMARS',\n",
       " ';',\n",
       " 'IT',\n",
       " 'SOMEHOW',\n",
       " 'MILDLY',\n",
       " 'REMINDED',\n",
       " 'HIM',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " 'MORTALITY',\n",
       " '.',\n",
       " '\"',\n",
       " 'WHILE',\n",
       " 'YOU',\n",
       " 'TAKE',\n",
       " 'IN',\n",
       " 'HAND',\n",
       " 'TO',\n",
       " 'SCHOOL',\n",
       " 'OTHERS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'TO',\n",
       " 'TEACH',\n",
       " 'THEM',\n",
       " 'BY',\n",
       " 'WHAT',\n",
       " 'NAME',\n",
       " 'A',\n",
       " 'WHALE',\n",
       " '-',\n",
       " 'FISH',\n",
       " 'IS',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'CALLED',\n",
       " 'IN',\n",
       " 'OUR',\n",
       " 'TONGUE',\n",
       " 'LEAVING',\n",
       " 'OUT',\n",
       " ',',\n",
       " 'THROUGH',\n",
       " 'IGNORANCE',\n",
       " ',',\n",
       " 'THE',\n",
       " 'LETTER',\n",
       " 'H',\n",
       " ',',\n",
       " 'WHICH',\n",
       " 'ALMOST',\n",
       " 'ALONE',\n",
       " 'MAKETH',\n",
       " 'THE',\n",
       " 'SIGNIFICATION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'WORD',\n",
       " ',',\n",
       " 'YOU',\n",
       " 'DELIVER',\n",
       " 'THAT',\n",
       " 'WHICH',\n",
       " 'IS',\n",
       " 'NOT',\n",
       " 'TRUE',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HACKLUYT',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'SW',\n",
       " '.',\n",
       " 'AND',\n",
       " 'DAN',\n",
       " '.',\n",
       " 'HVAL',\n",
       " '.',\n",
       " 'THIS',\n",
       " 'ANIMAL',\n",
       " 'IS',\n",
       " 'NAMED',\n",
       " 'FROM',\n",
       " 'ROUNDNESS',\n",
       " 'OR',\n",
       " 'ROLLING',\n",
       " ';',\n",
       " 'FOR',\n",
       " 'IN',\n",
       " 'DAN',\n",
       " '.',\n",
       " 'HVALT',\n",
       " 'IS',\n",
       " 'ARCHED',\n",
       " 'OR',\n",
       " 'VAULTED',\n",
       " '.\"',\n",
       " '--',\n",
       " 'WEBSTER',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'MORE',\n",
       " 'IMMEDIATELY',\n",
       " 'FROM',\n",
       " 'THE',\n",
       " 'DUT',\n",
       " '.',\n",
       " 'AND',\n",
       " 'GER',\n",
       " '.',\n",
       " 'WALLEN',\n",
       " ';',\n",
       " 'A',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " 'WALW',\n",
       " '-',\n",
       " 'IAN',\n",
       " ',',\n",
       " 'TO',\n",
       " 'ROLL',\n",
       " ',',\n",
       " 'TO',\n",
       " 'WALLOW',\n",
       " '.\"',\n",
       " '--',\n",
       " 'RICHARDSON',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " ',',\n",
       " 'GREEK',\n",
       " '.',\n",
       " 'CETUS',\n",
       " ',',\n",
       " 'LATIN',\n",
       " '.',\n",
       " 'WHOEL',\n",
       " ',',\n",
       " 'ANGLO',\n",
       " '-',\n",
       " 'SAXON',\n",
       " '.',\n",
       " 'HVALT',\n",
       " ',',\n",
       " 'DANISH',\n",
       " '.',\n",
       " 'WAL',\n",
       " ',',\n",
       " 'DUTCH',\n",
       " '.',\n",
       " 'HWAL',\n",
       " ',',\n",
       " 'SWEDISH',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ICELANDIC',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ENGLISH',\n",
       " '.',\n",
       " 'BALEINE',\n",
       " ',',\n",
       " 'FRENCH',\n",
       " '.',\n",
       " 'BALLENA',\n",
       " ',',\n",
       " 'SPANISH',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'FEGEE',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'ERROMANGOAN',\n",
       " '.',\n",
       " 'EXTRACTS',\n",
       " '(',\n",
       " 'SUPPLIED',\n",
       " 'BY',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'LIBRARIAN',\n",
       " ').',\n",
       " 'IT',\n",
       " 'WILL',\n",
       " 'BE',\n",
       " 'SEEN',\n",
       " 'THAT',\n",
       " 'THIS',\n",
       " 'MERE',\n",
       " 'PAINSTAKING',\n",
       " 'BURROWER',\n",
       " 'AND',\n",
       " 'GRUB',\n",
       " '-',\n",
       " 'WORM',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'POOR',\n",
       " 'DEVIL',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " 'APPEARS',\n",
       " 'TO',\n",
       " 'HAVE',\n",
       " 'GONE',\n",
       " 'THROUGH',\n",
       " 'THE',\n",
       " 'LONG',\n",
       " 'VATICANS',\n",
       " 'AND',\n",
       " 'STREET',\n",
       " '-',\n",
       " 'STALLS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'EARTH',\n",
       " ',',\n",
       " 'PICKING',\n",
       " 'UP',\n",
       " 'WHATEVER',\n",
       " 'RANDOM',\n",
       " 'ALLUSIONS',\n",
       " 'TO',\n",
       " 'WHALES',\n",
       " 'HE',\n",
       " 'COULD',\n",
       " 'ANYWAYS',\n",
       " 'FIND',\n",
       " 'IN',\n",
       " 'ANY',\n",
       " 'BOOK',\n",
       " 'WHATSOEVER',\n",
       " ',',\n",
       " 'SACRED',\n",
       " 'OR',\n",
       " 'PROFANE',\n",
       " '.',\n",
       " 'THEREFORE',\n",
       " 'YOU',\n",
       " 'MUST',\n",
       " 'NOT',\n",
       " ',',\n",
       " 'IN',\n",
       " 'EVERY',\n",
       " 'CASE',\n",
       " 'AT',\n",
       " 'LEAST',\n",
       " ',',\n",
       " 'TAKE',\n",
       " 'THE',\n",
       " 'HIGGLEDY',\n",
       " '-',\n",
       " 'PIGGLEDY',\n",
       " 'WHALE',\n",
       " 'STATEMENTS',\n",
       " ',',\n",
       " 'HOWEVER',\n",
       " 'AUTHENTIC',\n",
       " ',',\n",
       " 'IN',\n",
       " 'THESE',\n",
       " 'EXTRACTS',\n",
       " ',',\n",
       " 'FOR',\n",
       " 'VERITABLE',\n",
       " 'GOSPEL',\n",
       " 'CETOLOGY',\n",
       " '.',\n",
       " 'FAR',\n",
       " 'FROM',\n",
       " 'IT',\n",
       " '.',\n",
       " 'AS',\n",
       " 'TOUCHING',\n",
       " 'THE',\n",
       " 'ANCIENT',\n",
       " 'AUTHORS',\n",
       " 'GENERALLY',\n",
       " ',',\n",
       " 'AS',\n",
       " 'WELL',\n",
       " 'AS',\n",
       " 'THE',\n",
       " 'POETS',\n",
       " 'HERE',\n",
       " 'APPEARING',\n",
       " ',',\n",
       " 'THESE',\n",
       " 'EXTRACTS',\n",
       " 'ARE',\n",
       " 'SOLELY',\n",
       " 'VALUABLE',\n",
       " 'OR',\n",
       " 'ENTERTAINING',\n",
       " ',',\n",
       " 'AS',\n",
       " 'AFFORDING',\n",
       " 'A',\n",
       " 'GLANCING',\n",
       " 'BIRD',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'EYE',\n",
       " 'VIEW',\n",
       " 'OF',\n",
       " 'WHAT',\n",
       " 'HAS',\n",
       " 'BEEN',\n",
       " 'PROMISCUOUSLY',\n",
       " 'SAID',\n",
       " ',',\n",
       " 'THOUGHT',\n",
       " ',',\n",
       " 'FANCIED',\n",
       " ',',\n",
       " 'AND',\n",
       " 'SUNG',\n",
       " 'OF',\n",
       " 'LEVIATHAN',\n",
       " ',',\n",
       " 'BY',\n",
       " 'MANY',\n",
       " 'NATIONS',\n",
       " 'AND',\n",
       " 'GENERATIONS',\n",
       " ',',\n",
       " 'INCLUDING',\n",
       " 'OUR',\n",
       " 'OWN',\n",
       " '.',\n",
       " 'SO',\n",
       " 'FARE',\n",
       " 'THEE',\n",
       " 'WELL',\n",
       " ',',\n",
       " 'POOR',\n",
       " 'DEVIL',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " ',',\n",
       " 'WHOSE',\n",
       " 'COMMENTATOR',\n",
       " 'I',\n",
       " 'AM',\n",
       " '.',\n",
       " 'THOU',\n",
       " 'BELONGEST',\n",
       " 'TO',\n",
       " 'THAT',\n",
       " 'HOPELESS',\n",
       " ',',\n",
       " 'SALLOW',\n",
       " 'TRIBE',\n",
       " 'WHICH',\n",
       " 'NO',\n",
       " 'WINE',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'WORLD',\n",
       " 'WILL',\n",
       " 'EVER',\n",
       " 'WARM',\n",
       " ';',\n",
       " 'AND',\n",
       " 'FOR',\n",
       " 'WHOM',\n",
       " 'EVEN',\n",
       " 'PALE',\n",
       " 'SHERRY',\n",
       " 'WOULD',\n",
       " 'BE',\n",
       " 'TOO',\n",
       " 'ROSY',\n",
       " '-',\n",
       " 'STRONG',\n",
       " ';',\n",
       " 'BUT',\n",
       " 'WITH',\n",
       " 'WHOM',\n",
       " 'ONE',\n",
       " 'SOMETIMES',\n",
       " 'LOVES',\n",
       " 'TO',\n",
       " 'SIT',\n",
       " ',',\n",
       " 'AND',\n",
       " 'FEEL',\n",
       " 'POOR',\n",
       " '-',\n",
       " 'DEVILISH',\n",
       " ',',\n",
       " 'TOO',\n",
       " ';',\n",
       " 'AND',\n",
       " 'GROW',\n",
       " 'CONVIVIAL',\n",
       " 'UPON',\n",
       " 'TEARS',\n",
       " ';',\n",
       " 'AND',\n",
       " 'SAY',\n",
       " 'TO',\n",
       " 'THEM',\n",
       " 'BLUNTLY',\n",
       " ',',\n",
       " 'WITH',\n",
       " 'FULL',\n",
       " 'EYES',\n",
       " 'AND',\n",
       " 'EMPTY',\n",
       " 'GLASSES',\n",
       " ',',\n",
       " 'AND',\n",
       " 'IN',\n",
       " 'NOT',\n",
       " 'ALTOGETHER',\n",
       " 'UNPLEASANT',\n",
       " 'SADNESS',\n",
       " '--',\n",
       " 'GIVE',\n",
       " 'IT',\n",
       " 'UP',\n",
       " ',',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUBS',\n",
       " '!',\n",
       " 'FOR',\n",
       " 'BY',\n",
       " 'HOW',\n",
       " 'MUCH',\n",
       " 'THE',\n",
       " 'MORE',\n",
       " 'PAINS',\n",
       " 'YE',\n",
       " 'TAKE',\n",
       " 'TO',\n",
       " 'PLEASE',\n",
       " 'THE',\n",
       " 'WORLD',\n",
       " ',',\n",
       " 'BY',\n",
       " 'SO',\n",
       " 'MUCH',\n",
       " 'THE',\n",
       " 'MORE',\n",
       " 'SHALL',\n",
       " 'YE',\n",
       " 'FOR',\n",
       " 'EVER',\n",
       " 'GO',\n",
       " 'THANKLESS',\n",
       " '!',\n",
       " 'WOULD',\n",
       " 'THAT',\n",
       " 'I',\n",
       " 'COULD',\n",
       " 'CLEAR',\n",
       " 'OUT',\n",
       " 'HAMPTON',\n",
       " 'COURT',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'TUILERIES',\n",
       " 'FOR',\n",
       " 'YE',\n",
       " '!',\n",
       " 'BUT',\n",
       " 'GULP',\n",
       " 'DOWN',\n",
       " 'YOUR',\n",
       " 'TEARS',\n",
       " 'AND',\n",
       " 'HIE',\n",
       " 'ALOFT',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'ROYAL',\n",
       " '-',\n",
       " 'MAST',\n",
       " 'WITH',\n",
       " 'YOUR',\n",
       " 'HEARTS',\n",
       " ';',\n",
       " 'FOR',\n",
       " 'YOUR',\n",
       " 'FRIENDS',\n",
       " 'WHO',\n",
       " 'HAVE',\n",
       " 'GONE',\n",
       " 'BEFORE',\n",
       " 'ARE',\n",
       " 'CLEARING',\n",
       " 'OUT',\n",
       " 'THE',\n",
       " 'SEVEN',\n",
       " '-',\n",
       " 'STORIED',\n",
       " 'HEAVENS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'MAKING',\n",
       " 'REFUGEES',\n",
       " 'OF',\n",
       " 'LONG',\n",
       " '-',\n",
       " 'PAMPERED',\n",
       " 'GABRIEL',\n",
       " ',',\n",
       " 'MICHAEL',\n",
       " ',',\n",
       " 'AND',\n",
       " 'RAPHAEL',\n",
       " ',',\n",
       " 'AGAINST',\n",
       " 'YOUR',\n",
       " 'COMING',\n",
       " '.',\n",
       " 'HERE',\n",
       " 'YE',\n",
       " 'STRIKE',\n",
       " 'BUT',\n",
       " 'SPLINTERED',\n",
       " 'HEARTS',\n",
       " 'TOGETHER',\n",
       " '--',\n",
       " 'THERE',\n",
       " ',',\n",
       " 'YE',\n",
       " 'SHALL',\n",
       " 'STRIKE',\n",
       " 'UNSPLINTERABLE',\n",
       " 'GLASSES',\n",
       " '!',\n",
       " 'EXTRACTS',\n",
       " '.',\n",
       " '\"',\n",
       " 'AND',\n",
       " 'GOD',\n",
       " 'CREATED',\n",
       " 'GREAT',\n",
       " 'WHALES',\n",
       " '.\"',\n",
       " '--',\n",
       " 'GENESIS',\n",
       " '.',\n",
       " '\"',\n",
       " 'LEVIATHAN',\n",
       " 'MAKETH',\n",
       " 'A',\n",
       " 'PATH',\n",
       " 'TO',\n",
       " 'SHINE',\n",
       " 'AFTER',\n",
       " 'HIM',\n",
       " ';',\n",
       " 'ONE',\n",
       " 'WOULD',\n",
       " 'THINK',\n",
       " 'THE',\n",
       " 'DEEP',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'HOARY',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JOB',\n",
       " '.',\n",
       " '\"',\n",
       " 'NOW',\n",
       " 'THE',\n",
       " 'LORD',\n",
       " 'HAD',\n",
       " 'PREPARED',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'FISH',\n",
       " 'TO',\n",
       " 'SWALLOW',\n",
       " 'UP',\n",
       " 'JONAH',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JONAH',\n",
       " '.',\n",
       " '\"',\n",
       " 'THERE',\n",
       " 'GO',\n",
       " 'THE',\n",
       " 'SHIPS',\n",
       " ';',\n",
       " 'THERE',\n",
       " 'IS',\n",
       " 'THAT',\n",
       " 'LEVIATHAN',\n",
       " 'WHOM',\n",
       " 'THOU',\n",
       " 'HAST',\n",
       " 'MADE',\n",
       " 'TO',\n",
       " 'PLAY',\n",
       " 'THEREIN',\n",
       " '.\"',\n",
       " '--',\n",
       " 'PSALMS',\n",
       " '.',\n",
       " '\"',\n",
       " 'IN',\n",
       " 'THAT',\n",
       " 'DAY',\n",
       " ',',\n",
       " 'THE',\n",
       " 'LORD',\n",
       " 'WITH',\n",
       " 'HIS',\n",
       " 'SORE',\n",
       " ',',\n",
       " 'AND',\n",
       " 'GREAT',\n",
       " ',',\n",
       " 'AND',\n",
       " 'STRONG',\n",
       " 'SWORD',\n",
       " ',',\n",
       " 'SHALL',\n",
       " 'PUNISH',\n",
       " 'LEVIATHAN',\n",
       " 'THE',\n",
       " 'PIERCING',\n",
       " 'SERPENT',\n",
       " ',',\n",
       " 'EVEN',\n",
       " 'LEVIATHAN',\n",
       " 'THAT',\n",
       " 'CROOKED',\n",
       " 'SERPENT',\n",
       " ';',\n",
       " 'AND',\n",
       " 'HE',\n",
       " 'SHALL',\n",
       " 'SLAY',\n",
       " 'THE',\n",
       " 'DRAGON',\n",
       " 'THAT',\n",
       " 'IS',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " '.\"',\n",
       " '--',\n",
       " 'ISAIAH',\n",
       " '\"',\n",
       " 'AND',\n",
       " 'WHAT',\n",
       " 'THING',\n",
       " 'SOEVER',\n",
       " 'BESIDES',\n",
       " 'COMETH',\n",
       " 'WITHIN',\n",
       " 'THE',\n",
       " 'CHAOS',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'MONSTER',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'MOUTH',\n",
       " ',',\n",
       " 'BE',\n",
       " 'IT',\n",
       " 'BEAST',\n",
       " ',',\n",
       " 'BOAT',\n",
       " ',',\n",
       " 'OR',\n",
       " 'STONE',\n",
       " ',',\n",
       " 'DOWN',\n",
       " 'IT',\n",
       " 'GOES',\n",
       " 'ALL',\n",
       " 'INCONTINENTLY',\n",
       " 'THAT',\n",
       " 'FOUL',\n",
       " 'GREAT',\n",
       " 'SWALLOW',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'PERISHETH',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'BOTTOMLESS',\n",
       " 'GULF',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " 'PAUNCH',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLUTARCH',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'MORALS',\n",
       " '.',\n",
       " '\"',\n",
       " 'THE',\n",
       " 'INDIAN',\n",
       " 'SEA',\n",
       " 'BREEDETH',\n",
       " 'THE',\n",
       " 'MOST',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'BIGGEST',\n",
       " 'FISHES',\n",
       " 'THAT',\n",
       " 'ARE',\n",
       " ':',\n",
       " 'AMONG',\n",
       " 'WHICH',\n",
       " 'THE',\n",
       " 'WHALES',\n",
       " 'AND',\n",
       " 'WHIRLPOOLES',\n",
       " 'CALLED',\n",
       " 'BALAENE',\n",
       " ',',\n",
       " 'TAKE',\n",
       " 'UP',\n",
       " 'AS',\n",
       " 'MUCH',\n",
       " 'IN',\n",
       " 'LENGTH',\n",
       " 'AS',\n",
       " 'FOUR',\n",
       " 'ACRES',\n",
       " 'OR',\n",
       " 'ARPENS',\n",
       " 'OF',\n",
       " 'LAND',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLINY',\n",
       " '.',\n",
       " '\"',\n",
       " 'SCARCELY',\n",
       " 'HAD',\n",
       " 'WE',\n",
       " 'PROCEEDED',\n",
       " 'TWO',\n",
       " 'DAYS',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " ',',\n",
       " 'WHEN',\n",
       " 'ABOUT',\n",
       " 'SUNRISE',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'MANY',\n",
       " 'WHALES',\n",
       " 'AND',\n",
       " 'OTHER',\n",
       " 'MONSTERS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " ',',\n",
       " 'APPEARED',\n",
       " '.',\n",
       " 'AMONG',\n",
       " 'THE',\n",
       " 'FORMER',\n",
       " ',',\n",
       " 'ONE',\n",
       " 'WAS',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'MOST',\n",
       " 'MONSTROUS',\n",
       " 'SIZE',\n",
       " '.',\n",
       " '...',\n",
       " 'THIS',\n",
       " 'CAME',\n",
       " 'TOWARDS',\n",
       " 'US',\n",
       " ',',\n",
       " 'OPEN',\n",
       " '-',\n",
       " 'MOUTHED',\n",
       " ',',\n",
       " 'RAISING',\n",
       " 'THE',\n",
       " 'WAVES',\n",
       " 'ON',\n",
       " 'ALL',\n",
       " 'SIDES',\n",
       " ',',\n",
       " 'AND',\n",
       " 'BEATING',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " 'BEFORE',\n",
       " 'HIM',\n",
       " 'INTO',\n",
       " 'A',\n",
       " 'FOAM',\n",
       " '.\"',\n",
       " '--',\n",
       " 'TOOKE',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'LUCIAN',\n",
       " '.',\n",
       " '\"',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " '.\"',\n",
       " '\"',\n",
       " 'HE',\n",
       " 'VISITED',\n",
       " 'THIS',\n",
       " 'COUNTRY',\n",
       " 'ALSO',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'VIEW',\n",
       " 'OF',\n",
       " 'CATCHING',\n",
       " 'HORSE',\n",
       " '-',\n",
       " 'WHALES',\n",
       " ',',\n",
       " 'WHICH',\n",
       " 'HAD',\n",
       " 'BONES',\n",
       " 'OF',\n",
       " 'VERY',\n",
       " 'GREAT',\n",
       " 'VALUE',\n",
       " 'FOR',\n",
       " 'THEIR',\n",
       " 'TEETH',\n",
       " ',',\n",
       " 'OF',\n",
       " 'WHICH',\n",
       " 'HE',\n",
       " 'BROUGHT',\n",
       " 'SOME',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'KING',\n",
       " '.',\n",
       " '...',\n",
       " 'THE',\n",
       " 'BEST',\n",
       " 'WHALES',\n",
       " 'WERE',\n",
       " 'CATCHED',\n",
       " 'IN',\n",
       " 'HIS',\n",
       " 'OWN',\n",
       " 'COUNTRY',\n",
       " ',',\n",
       " 'OF',\n",
       " 'WHICH',\n",
       " 'SOME',\n",
       " 'WERE',\n",
       " 'FORTY',\n",
       " '-',\n",
       " 'EIGHT',\n",
       " ',',\n",
       " 'SOME',\n",
       " 'FIFTY',\n",
       " 'YARDS',\n",
       " 'LONG',\n",
       " '.',\n",
       " 'HE',\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.upper() for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17231"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word.lower() for word in text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16948"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word.lower() for word in text1 if word.isalpha()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word length is less than 5\n"
     ]
    }
   ],
   "source": [
    "word = 'cat'\n",
    "if len(word) < 5:\n",
    "    print('word length is less than 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(word) >= 5:\n",
    "        print('word length is greater than or equal to 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n",
      "me\n",
      "Ishmael\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in ['Call', 'me', 'Ishmael', '.']:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n",
      "Ishmael\n"
     ]
    }
   ],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    "for xyzzy in sent1:\n",
    "    if xyzzy.endswith('l'):\n",
    "        print(xyzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call is a titlecase word\n",
      "me is a lowercase word\n",
      "Ishmael is a titlecase word\n",
      ". is punctation\n"
     ]
    }
   ],
   "source": [
    "for token in sent1:\n",
    "        if token.islower():\n",
    "            print(token, 'is a lowercase word')\n",
    "        elif token.istitle():\n",
    "            print(token, 'is a titlecase word')\n",
    "        else:\n",
    "            print(token, 'is punctation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancient ceiling conceit conceited conceive conscience conscientious conscientiously deceitful deceive deceived deceiving deficiencies deficiency deficient delicacies excellencies fancied insufficiency insufficient legacies perceive perceived perceiving prescience prophecies receipt receive received receiving society species sufficient sufficiently undeceive undeceiving "
     ]
    }
   ],
   "source": [
    "tricky = sorted(w for w in set(text2) if 'cie' in w or 'cei' in w)\n",
    "for word in tricky:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = 'Monty'\n",
    "bar = foo\n",
    "foo = 'Python'\n",
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Bodkin']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = ['Monty', 'Python']\n",
    "bar = foo\n",
    "foo[1] = 'Bodkin'\n",
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty = []\n",
    "nested = [empty, empty, empty]\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested[1].append('Python')\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested = [[]] * 3\n",
    "nested[1].append('Python')\n",
    "nested[1] = ['Monty']\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "python = ['Python']\n",
    "snake_nest = [python] * size\n",
    "snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = random.choice(range(size))\n",
    "snake_nest[position] = ['Python']\n",
    "snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140601059750856,\n",
       " 140600353849864,\n",
       " 140600353849864,\n",
       " 140600353849864,\n",
       " 140600353849864]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id(snake) for snake in snake_nest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['dog']\n"
     ]
    }
   ],
   "source": [
    "mixed = ['cat', '', ['dog'], []]\n",
    "for element in mixed:\n",
    "    if element:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "animals = ['cat', 'dog']\n",
    "if 'cat' in animals:\n",
    "    print(1)\n",
    "elif 'dog' in animals:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']\n",
    "all(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'fem', 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'walk', 'fem', 3\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fem', 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t', 'the', 'turned')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'I turned off the spectroroute'\n",
    "text = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "pair = (6, 'turned')\n",
    "raw[2], text[3], pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ute', ['off', 'the', 'spectroroute'], (6, 'turned'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[-3:], text[-3:], pair[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw), len(text), len(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'Red', 'lorry', 'red', 'yellow']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    "text = nltk.word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(text)\n",
    "sorted(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red: 1; lorry: 4; ,: 3; yellow: 2; red: 1; .: 1; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'the', 'spectroroute', 'off']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in fdist:\n",
    "    print(key + ':', fdist[key], end='; ')\n",
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "words[2], words[3], words[4] = words[3], words[4], words[2]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'the', 'spectroroute', 'off']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tmp = words[2]\n",
    "words[2] = words[3]\n",
    "words[3] = words[4]\n",
    "words[4] = tmp\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fe0101b4988>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    "zip(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'noun'),\n",
       " ('turned', 'verb'),\n",
       " ('off', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('spectroroute', 'noun')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.nps_chat.words()\n",
    "cut = int(0.9 * len(text))\n",
    "training_data, test_data = text[:cut], text[cut:]\n",
    "text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'I turned off the spectroroute'.split()\n",
    "wordlens = [(len(word), word) for word in words]\n",
    "wordlens.sort()\n",
    "' '.join(w for (_, w) in wordlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turned', 'VBD', ['t3:nd', 't3`nd'])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = [\n",
    "    ('the', 'det', ['Di:', 'D@']),\n",
    "    ('off', 'prep', ['Qf', '0:f'])\n",
    "]\n",
    "lexicon.sort()\n",
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])\n",
    "del lexicon[0]\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1c55fc1667a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m \u001b[0mlexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "lexicon = [\n",
    "    ('the', 'det', ['Di:', 'D@']),\n",
    "    ('off', 'prep', ['Qf', '0:f'])\n",
    "]\n",
    "lexicon = tuple(lexicon)\n",
    "lexicon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-190afce4dcb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "lexicon[1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object doesn't support item deletion",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-0ba66aa11bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object doesn't support item deletion"
     ]
    }
   ],
   "source": [
    "del lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " '``',\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone, \\\"it means just what I choose it to mean - neither more nor less.\"'''\n",
    "[w.lower() for w in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "print(max([w.lower() for w in nltk.word_tokenize(text)])) # entire structure is passed at once\n",
    "print(max(w.lower() for w in nltk.word_tokenize(text))) # fed through a stream, more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: A1: Python and Jupyter\n",
      "OK, version v1.13.11\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "LoadingException",
     "evalue": "Cannot load OK test tests/q32.py",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSerializeException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/sources/ok_test/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, parameter, assign)\u001b[0m\n\u001b[1;32m     50\u001b[0m                                     \u001b[0massign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                                     assign.cmd_args.timeout, **test)}\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/sources/common/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                                 'argument {}'.format(attr))\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_instantiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/sources/ok_test/models.py\u001b[0m in \u001b[0;36mpost_instantiation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m'type'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Suites must have field \"type\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msuite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuite_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSerializeException\u001b[0m: Suites must have field \"type\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLoadingException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92dabc7498ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a1.ok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/api/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, cmd_args, debug)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mok_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'client'\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Get top-level ok logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mok_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Attempt a login with enviornment based tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlogin_with_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/api/assignment.py\u001b[0m in \u001b[0;36mload_assignment\u001b[0;34m(filepath, cmd_args)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcmd_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mcmd_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAssignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/sources/common/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 raise ex.SerializeException('__init__() missing expected '\n\u001b[1;32m    186\u001b[0m                                 'argument {}'.format(attr))\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_instantiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/api/assignment.py\u001b[0m in \u001b[0;36mpost_instantiation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_instantiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_protocols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         self.specified_tests = self._resolve_specified_tests(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/api/assignment.py\u001b[0m in \u001b[0;36m_load_tests\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0mtest_name\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/client/sources/ok_test/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, parameter, assign)\u001b[0m\n\u001b[1;32m     51\u001b[0m                                     assign.cmd_args.timeout, **test)}\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadingException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot load OK test {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mLoadingException\u001b[0m: Cannot load OK test tests/q32.py"
     ]
    }
   ],
   "source": [
    "from client.api.notebook import Notebook\n",
    "\n",
    "ok = Notebook('a1.ok')\n",
    "\n",
    "ok.auth(inline=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving notebook... Saved 'A1-python-jupyter.ipynb'.\n",
      "Submit... 100% complete\n",
      "Submission successful for user: bakuzen@gmail.com\n",
      "URL: https://okpy.org/boisestate/cs4-533/sp19/a1/submissions/D9B6Vq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
