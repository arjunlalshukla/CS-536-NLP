{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Grounded, Lexical Semantics\n",
    "\n",
    "## Natural Language Processing - Boise State University\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Attached to the corresponding Trello card for this assignment are the files `features.txt` and `segmented-labeled.txt` which have data for a reference resolution task. I have already done a lot of the data munging for you. The rdg_munging.html / rdg_munging.ipynb notebook shows how I did that. At the very end I saved two data frames as two pickles named `scenedata.pkl` and `refexpdata.pkl`. You will use these two files. \n",
    "* You are to use the `scenedata.pkl` and `refexpdata.pkl` files to train logistic regression classifiers that take low-level object ('visual') data as features and produce a probability that an object matches a word's classifier. \n",
    "\n",
    "**scenedata** scenes are separated by `episodeid`. For each `eposodeid`, there are 8 images, each with an `imageid`. For each image, there could be between 1 and 7 `pieceid` depending on the scene type. \n",
    "\n",
    "Below is an example Scene where each image has two pieces (see http://www.sigdial.org/workshops/conference17/proceedings/pdf/SIGDIAL30.pdf for more information):\n",
    "\n",
    "![title](rdg_scene_example.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these kinds of scenes, the task was for the *Director* who knew which object needed to be selected, was to instruct the *Matcher* just which object that was. The *Director*'s game screen had the same images on it, but they were usually in a different order, forcing the *Director* to describe the objects in the image rather than the image placement on the grid (e.g., so a *Director* couldn't just say something like \"first row, second column\") to indicate an image).\n",
    "\n",
    "The goal of this assignment is to use the data to train logistic regression classifiers for each word in the corpus and evaluate how well they can be used for resolving references to visual objects. **Note** that the goal is to resolve references to individual objects, not individual images (i.e., images can have more than one object in them). \n",
    "\n",
    "First, load the data and get an idea what it is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `scenes` is like a database that has the features of each object in each image for each episode. \n",
    "\n",
    "The dataframe `refs` has the referring expressions, where each each `id` represents an individual referring expression (i.e., grouping by id groups all the words in a referring rexpression), the `episodeid`, `imageid`, and `targetid` denote the episode, image of the episode, and target object in the image that is being referred by that referring expression. Note that for all referring expressions grouped by an id, the `id`, `episodeid`, `imageid`, and `targetid` are the same. The only thing that is different are the words in the word column. The words are ordered by row. (See example in the above cell.)\n",
    "\n",
    "Note that the targetid is the pieceid for the referred object in a particular `episodeid`/`imageid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = pd.read_pickle('scenedata.pkl')\n",
    "refs = pd.read_pickle('refexpdata.pkl')\n",
    "\n",
    "refs['type'] = refs.episodeid.map(lambda x: x.split('/')[0])\n",
    "refs = refs[refs.type == 'Set0'] # we only use images where there is only one object in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pieceid', 'imageid', 'episodeid', 'r', 'g', 'b', 'h', 's', 'v',\n",
       "       'orientation', 'num_edges', 'pos_x', 'pos_y', 'h_skew_left-skewed',\n",
       "       'h_skew_right-skewed', 'h_skew_symmetric', 'v_skew_bottom-skewed',\n",
       "       'v_skew_symmetric', 'v_skew_top-skewed', 'c_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pieceid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>episodeid</th>\n",
       "      <th>r</th>\n",
       "      <th>g</th>\n",
       "      <th>b</th>\n",
       "      <th>h</th>\n",
       "      <th>s</th>\n",
       "      <th>v</th>\n",
       "      <th>orientation</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>pos_x</th>\n",
       "      <th>pos_y</th>\n",
       "      <th>h_skew_left-skewed</th>\n",
       "      <th>h_skew_right-skewed</th>\n",
       "      <th>h_skew_symmetric</th>\n",
       "      <th>v_skew_bottom-skewed</th>\n",
       "      <th>v_skew_symmetric</th>\n",
       "      <th>v_skew_top-skewed</th>\n",
       "      <th>c_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>86.480225</td>\n",
       "      <td>57.164215</td>\n",
       "      <td>46.304261</td>\n",
       "      <td>8.293657</td>\n",
       "      <td>127.795376</td>\n",
       "      <td>86.661635</td>\n",
       "      <td>5.742743</td>\n",
       "      <td>8</td>\n",
       "      <td>199</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257.870122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>79.555440</td>\n",
       "      <td>74.452909</td>\n",
       "      <td>59.535351</td>\n",
       "      <td>22.514740</td>\n",
       "      <td>74.233586</td>\n",
       "      <td>79.337073</td>\n",
       "      <td>41.519360</td>\n",
       "      <td>10</td>\n",
       "      <td>222</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>273.065926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>130.428545</td>\n",
       "      <td>111.250280</td>\n",
       "      <td>86.211567</td>\n",
       "      <td>17.137593</td>\n",
       "      <td>94.268750</td>\n",
       "      <td>131.000560</td>\n",
       "      <td>-7.716261</td>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>259.094577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>69.591751</td>\n",
       "      <td>55.848775</td>\n",
       "      <td>83.484260</td>\n",
       "      <td>135.273859</td>\n",
       "      <td>92.572226</td>\n",
       "      <td>83.479976</td>\n",
       "      <td>-21.408810</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>268.486499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>36.108723</td>\n",
       "      <td>79.887808</td>\n",
       "      <td>112.033928</td>\n",
       "      <td>102.723919</td>\n",
       "      <td>177.755478</td>\n",
       "      <td>112.230646</td>\n",
       "      <td>42.677817</td>\n",
       "      <td>6</td>\n",
       "      <td>220</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>277.418456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pieceid imageid episodeid           r           g           b           h  \\\n",
       "0        0       1    Set0/1   86.480225   57.164215   46.304261    8.293657   \n",
       "1        0       2    Set0/1   79.555440   74.452909   59.535351   22.514740   \n",
       "2        0       3    Set0/1  130.428545  111.250280   86.211567   17.137593   \n",
       "3        0       4    Set0/1   69.591751   55.848775   83.484260  135.273859   \n",
       "4        0       5    Set0/1   36.108723   79.887808  112.033928  102.723919   \n",
       "\n",
       "            s           v  orientation  num_edges  pos_x  pos_y  \\\n",
       "0  127.795376   86.661635     5.742743          8    199    164   \n",
       "1   74.233586   79.337073    41.519360         10    222    159   \n",
       "2   94.268750  131.000560    -7.716261         12    203    161   \n",
       "3   92.572226   83.479976   -21.408810          8    222    151   \n",
       "4  177.755478  112.230646    42.677817          6    220    169   \n",
       "\n",
       "   h_skew_left-skewed  h_skew_right-skewed  h_skew_symmetric  \\\n",
       "0                   0                    1                 0   \n",
       "1                   1                    0                 0   \n",
       "2                   0                    0                 1   \n",
       "3                   0                    0                 1   \n",
       "4                   1                    0                 0   \n",
       "\n",
       "   v_skew_bottom-skewed  v_skew_symmetric  v_skew_top-skewed      c_diff  \n",
       "0                     1                 0                  0  257.870122  \n",
       "1                     0                 0                  1  273.065926  \n",
       "2                     1                 0                  0  259.094577  \n",
       "3                     0                 0                  1  268.486499  \n",
       "4                     0                 0                  1  277.418456  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'episodeid', 'imageid', 'target', 'word'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>episodeid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>target</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>reverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Set0/1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id episodeid imageid  target     word\n",
       "3   4    Set0/1       8       0     like\n",
       "3   4    Set0/1       8       0      off\n",
       "3   4    Set0/1       8       0       to\n",
       "3   4    Set0/1       8       0      the\n",
       "3   4    Set0/1       8       0     left\n",
       "3   4    Set0/1       8       0     like\n",
       "3   4    Set0/1       8       0        a\n",
       "3   4    Set0/1       8       0  reverse\n",
       "3   4    Set0/1       8       0        l"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs[refs.id == 4] # show the referring expression for id=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure and Hints\n",
    "\n",
    "* This was made easier for me using pandasql / pysqldf, but anything that can be done using pandasql/pydsqldf can be done using pandas merge functions. \n",
    "* You will need to somehow join/merge the refs with the data such that you can get the object features of the target objects (the key columns will be episodeid, imageid, and targetid/pieceid\n",
    "* Split your data into train/test. You can randomly choose 100 referring expressions (ids) for testing. \n",
    "* Training is tricky. You need to do the following for each word in the vocabulary:\n",
    "   * Get all of the features for the objects where that word was used. These are your positive training examples. \n",
    "   * Randomly choose features for objects where that word was *not* used. These are your negative training examples. \n",
    "   * You should have the same number of negative and positive training examples\n",
    "   * Use `0` to label the negative training examples and `1` to label to positive training examples. \n",
    "   * Train the logistic regression classifier using the labeleled positive and negative examples (penalty='l2' helps here). \n",
    "   * I recommend using a dictionary where key=word, value=classifier\n",
    "* Testing is also tricky. You need to make sure you are conducting a realistic test. You want to represent your data as if you are looking at a scene. That means, for a referring expression, you want the 8 corresponding images and all of the objects in those images. You then take the words in the referring expression, get their respective classifiers, and test them on each of the objects in each of the images. For each object, you will sum the probabilities that are returned for each classifier. The object with the highest score (i.e., the highest sum of probabilities) will be the guessed referent object. To calculate accuracy, you will check to see if that object's pieceid matches the targetid. If they do, then your accuracy increases. \n",
    "    * I was able to do testing using a query that joined the test and scene data into a dataframe such that all words and all objects were reprsented in individual rows. \n",
    "    * I then made a new column in that dataframe that was the probability of applying the word in a row to the object features in the same row. \n",
    "    * I then used a query to sum the results over the objects (accomplished by grouping by certain columns).\n",
    "    * I then used a query to find the max-scored object and compared that with the target. \n",
    "* For this assignment, your accuracy needs to be above 50%. That seems low, but at the best when there is one object in each of the 8 images, the baseline is 1/8 (12.5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
