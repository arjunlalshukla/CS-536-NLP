{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Grounded, Lexical Semantics\n",
    "\n",
    "## Natural Language Processing - Boise State University\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Attached to the corresponding Trello card for this assignment are the files `features.txt` and `segmented-labeled.txt` which have data for a reference resolution task. I have already done a lot of the data munging for you. The rdg_munging.html / rdg_munging.ipynb notebook shows how I did that. At the very end I saved two data frames as two pickles named `scenedata.pkl` and `refexpdata.pkl`. You will use these two files. \n",
    "* You are to use the `scenedata.pkl` and `refexpdata.pkl` files to train logistic regression classifiers that take low-level object ('visual') data as features and produce a probability that an object matches a word's classifier. \n",
    "\n",
    "**scenedata** scenes are separated by `episodeid`. For each `eposodeid`, there are 8 images, each with an `imageid`. For each image, there could be between 1 and 7 `pieceid` depending on the scene type. However, for this assignment we only care about cases where there is only 1 object in each image\n",
    "\n",
    "Below is an example Scene where each image has two pieces (see http://www.sigdial.org/workshops/conference17/proceedings/pdf/SIGDIAL30.pdf for more information):\n",
    "\n",
    "![title](rdg_scene_example.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these kinds of scenes, the task was for the *Director* who knew which object needed to be selected, was to instruct the *Matcher* just which object that was. The *Director*'s game screen had the same images on it, but they were usually in a different order, forcing the *Director* to describe the objects in the image rather than the image placement on the grid (e.g., so a *Director* couldn't just say something like \"first row, second column\") to indicate an image).\n",
    "\n",
    "The goal of this assignment is to use the data to train logistic regression classifiers for each word in the corpus and evaluate how well they can be used for resolving references to visual objects. **Note** that the goal is to resolve references to individual objects, not individual images (i.e., images can have more than one object in them). \n",
    "\n",
    "First, load the data and get an idea what it is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `scenes` is like a database that has the features of each object in each image for each episode. \n",
    "\n",
    "The dataframe `refs` has the referring expressions, where each each `id` represents an individual referring expression (i.e., grouping by id groups all the words in a referring rexpression), the `episodeid`, `imageid`, and `targetid` denote the episode, image of the episode, and target object in the image that is being referred by that referring expression. Note that for all referring expressions grouped by an id, the `id`, `episodeid`, `imageid`, and `targetid` are the same. The only thing that is different are the words in the word column. The words are ordered by row. (See example in the above cell.)\n",
    "\n",
    "Note that the targetid is the pieceid for the referred object in a particular `episodeid`/`imageid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = pd.read_pickle('scenedata.pkl')\n",
    "refs = pd.read_pickle('refexpdata.pkl')\n",
    "\n",
    "refs['type'] = refs.episodeid.map(lambda x: x.split('/')[0])\n",
    "refs = refs[refs.type == 'Set0'] # we only use images where there is only one object in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(scenes.pieceid))\n",
    "print(set(scenes.imageid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refs[refs.id == 4] # show the referring expression for id=4\n",
    "print(set(refs.imageid))\n",
    "for ID in set(refs.id):\n",
    "    ref = refs[refs.id == ID]\n",
    "    line = [set(ref.id), set(ref.imageid), set(ref.episodeid), set(ref.target)]\n",
    "    for word in ref['word']:\n",
    "        line.append(word)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure and Hints\n",
    "\n",
    "* This was made easier for me using pandasql / pysqldf, but anything that can be done using pandasql/pydsqldf can be done using pandas merge functions. \n",
    "* I split the data for you into train/test\n",
    "* Training is tricky. You need to do the following for each word in the vocabulary:\n",
    "   * Get all of the features for the objects where that word was used. These are your positive training examples. \n",
    "   * Randomly choose features for objects where that word was *not* used. These are your negative training examples. \n",
    "   * You should have the same number of negative and positive training examples\n",
    "   * Use `0` to label the negative training examples and `1` to label to positive training examples. \n",
    "   * Train the logistic regression classifier using the labeleled positive and negative examples (penalty='l2' helps here). \n",
    "   * I recommend using a dictionary where key=word, value=classifier\n",
    "* Testing is also tricky. You need to make sure you are conducting a realistic test. You want to represent your data as if you are looking at a scene. That means, for a referring expression, you want the 8 corresponding images and all of the objects in those images. You then take the words in the referring expression, get their respective classifiers, and test them on each of the objects in each of the images. For each object, you will sum the probabilities that are returned for each classifier. The object with the highest score (i.e., the highest sum of probabilities) will be the guessed referent object. To calculate accuracy, you will check to see if that object's pieceid matches the targetid. If they do, then your accuracy increases. \n",
    "    * I was able to do testing using a query that joined the test and scene data into a dataframe such that all words and all objects were reprsented in individual rows. \n",
    "    * I then made a new column in that dataframe that was the probability of applying the word in a row to the object features in the same row. \n",
    "    * I then used a query to sum the results over the objects (accomplished by grouping by certain columns).\n",
    "    * I then used a query to find the max-scored object and compared that with the target. \n",
    "* For this assignment, your accuracy needs to be above 50%. That seems low, but at the best when there is one object in each of the 8 images, the baseline is 1/8 (12.5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = refs\n",
    "data = scenes\n",
    "\n",
    "from pandasql import sqldf\n",
    "from pandasql import *\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# merge the data and res dataframes so we can get the targets' features\n",
    "#\n",
    "query = '''\n",
    "SELECT res.word, res.id, target, data.* \n",
    "FROM data \n",
    "INNER JOIN res\n",
    "ON data.episodeid = res.episodeid\n",
    "AND data.pieceid = res.target \n",
    "AND data.imageid = res.imageid\n",
    "ORDER BY id, data.episodeid\n",
    "\n",
    "'''\n",
    "\n",
    "positive = pysqldf(query)\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(positive.word)) # vocabulary\n",
    "len(set(positive.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "\n",
    "import random\n",
    "\n",
    "num_eval = 100\n",
    "\n",
    "eids = set(positive.id)\n",
    "test_eids = set(random.sample(eids, num_eval))\n",
    "train_eids = list(set(eids - test_eids))\n",
    "test_eids = list(test_eids)\n",
    "\n",
    "positive_train = positive[positive.id.isin(train_eids)]\n",
    "classifiers = {}\n",
    "for word in set(positive_train.word):\n",
    "    pos_tups = positive_train[positive_train.word == word]\n",
    "    neg_tups = positive_train[~positive_train.id.isin(set(pos_tups.id))]\n",
    "    #make sure we have equal positive and negative examples\n",
    "    if len(pos_tups) < len(neg_tups):\n",
    "        neg_tups = neg_tups.sample(frac=1)[:len(pos_tups)]\n",
    "    else:\n",
    "        pos_tups = pos_tups.sample(frac=1)[:len(neg_tups)]\n",
    "    exp_res = [1]*len(pos_tups) + [0]*len(neg_tups)\n",
    "    all_tups = pd.concat([pos_tups, neg_tups])\n",
    "    classifiers[word] = LogisticRegression()\n",
    "    classifiers[word].fit(all_tups.values[:,6:], exp_res)\n",
    "    #print(\"created classifier for \\\"\" + word + \"\\\"\")\n",
    "    \n",
    "test = positive[positive.id.isin(test_eids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test\n",
    "query = '''\n",
    "SELECT SUM(test.prob) AS sum, test.*\n",
    "FROM test\n",
    "GROUP BY r, g, b, h, s, v, \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
