{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "- We'll be using the [pymagnitude](https://github.com/plasticityai/magnitude) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\arjun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymagnitude import *\n",
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'data/fasttext-wiki-news-300d-1M.magnitude'\n",
    "#path = 'data/glove.6B.300d.magnitude'\n",
    "#path = 'data/GoogleNews-vectors-negative300.magnitude'\n",
    "path = 'data/glove.6B.50d.magnitude'\n",
    "# this isn't working: path = 'data/elmo_2x4096_512_2048cnn_2xhighway_weights.magnitude'\n",
    "\n",
    "vectors = Magnitude(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.dim # this is how big the vectors are for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cat\" in vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working [ 0.0547345 -0.0305866 -0.0075621]\n",
      "community [ 0.0276732  0.117468  -0.1533174]\n",
      "eight [0.0133356 0.0815326 0.1307856]\n",
      "groups [ 0.0933181 -0.0622403 -0.0163335]\n",
      "despite [-0.0066614  0.0074928 -0.0322814]\n",
      "level [-0.0736265  0.1976634  0.0354784]\n",
      "largest [0.1119611 0.0235172 0.0475007]\n",
      "whose [ 0.0633574  0.144303  -0.0080723]\n",
      "attacks [ 0.2780417 -0.1416092  0.1276424]\n",
      "germany [0.0529495 0.009489  0.0464709]\n"
     ]
    }
   ],
   "source": [
    "for key, vector in vectors[500:510]:\n",
    "    print(key, vector[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1027278, -0.1136787, -0.1218595], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.query(\"cat\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1027278, -0.1136787, -0.1218595], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.query([\"cat\",\"dog\"])[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.395473"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.distance(\"cat\", \"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1279846"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.distance(\"cat\", \"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.most_similar_to_given(\"cat\", [\"dog\", \"television\", \"laptop\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.doesnt_match([\"breakfast\", \"cereal\", \"dinner\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectors.most_similar(\"cat\", topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectors.most_similar(positive = [\"woman\", \"king\"], negative = [\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "\n",
    "- Given a document, determine the topic of the document\n",
    "- For this task, we'll use the Brown corpus of texts accessible via NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7afbba6b5845deb4c448d82808048d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "belles_lettres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98eb72e79314dfeab6dfac5d70314d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=75), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "editorial\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e045a4af930b4453baf9122f24362f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fiction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057ff24c20d54591906e2bea9de17f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "government\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed413dee7cd04a86b4d778c897be2a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hobbies\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2904548d3e3044a78e4abd30c55c90dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "humor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c97218fa58c4573920edbc3d93f35b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "learned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e628b9fb0013449898fedb3e774476cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lore\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddb8d66c29f4a3592e70aa02315e3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mystery\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664bad8f4f9249f0b05c1bc4a4054e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "news\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9c81457ca644b4b425b4570d7f2a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=44), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "religion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a643abecf6a482dbdce01e573860cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reviews\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e7edca81c841eaa647997f4aa846d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "romance\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe4001948f948f4b382b3a30321974b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "science_fiction\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efe7223d8704a87a85611399bf67617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from collections import defaultdict\n",
    "import tqdm # tqdm displays a progress bar\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "category_vectors = []\n",
    "\n",
    "cats = brown.categories()\n",
    "    \n",
    "# for each category\n",
    "for cat in cats:\n",
    "    print(cat)\n",
    "    # grab all of the documents\n",
    "    for fileid in tqdm(brown.fileids(categories=[cat])):\n",
    "        words = list(map(str.lower, brown.words(fileids=[fileid])))\n",
    "        # grab all of the words, find their embedding, sum all embeddings\n",
    "        word_sum = np.sum([vectors.query([w]) for w in words if w in vectors], axis=0) # why axis=0?\n",
    "        # add the now summed embedding to the list for this category\n",
    "        category_vectors.append((cat,word_sum))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keys,values=zip(*category_vectors) # unzip using a *\n",
    "\n",
    "data = pd.DataFrame({'cat':keys,'vectors':values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventure</td>\n",
       "      <td>[[101.48395, 49.925434, -35.528347, -92.13484,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adventure</td>\n",
       "      <td>[[93.14879, 49.615086, -33.30255, -89.50236, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adventure</td>\n",
       "      <td>[[93.08724, 25.093605, 1.5583314, -87.50236, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat                                            vectors\n",
       "0  adventure  [[101.48395, 49.925434, -35.528347, -92.13484,...\n",
       "1  adventure  [[93.14879, 49.615086, -33.30255, -89.50236, 1...\n",
       "2  adventure  [[93.08724, 25.093605, 1.5583314, -87.50236, 1..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute the baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random baseline 0.06666666666666667\n",
      "most common baseline?\n",
      "adventure 0.058\n",
      "belles_lettres 0.15\n",
      "editorial 0.054\n",
      "fiction 0.058\n",
      "government 0.06\n",
      "hobbies 0.072\n",
      "humor 0.018\n",
      "learned 0.16\n",
      "lore 0.096\n",
      "mystery 0.048\n",
      "news 0.088\n",
      "religion 0.034\n",
      "reviews 0.034\n",
      "romance 0.058\n",
      "science_fiction 0.012\n"
     ]
    }
   ],
   "source": [
    "print('random baseline {}'.format(1.0/len(cat)))\n",
    "\n",
    "print('most common baseline?')\n",
    "for cat in cats:\n",
    "    print(cat, len(data[data.cat==cat])/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 2), (450, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.sample(frac=0.1,random_state=200)\n",
    "train = data.drop(test.index)\n",
    "\n",
    "test.shape, train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\arjun\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((450, 50), (450, 15))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "le.fit(data.cat)\n",
    "y = le.transform(train.cat).reshape(-1, 1) # this is magic\n",
    "ohe.fit(y)\n",
    "y = ohe.transform(y)\n",
    "\n",
    "X = np.array([x[0] for x in train.vectors])\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "450/450 [==============================] - ETA: 27s - loss: 3.4178 - acc: 0.06 - ETA: 0s - loss: 3.1496 - acc: 0.0994 - 2s 5ms/step - loss: 3.1377 - acc: 0.0978\n",
      "Epoch 2/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.7243 - acc: 0.218 - ETA: 0s - loss: 3.0537 - acc: 0.102 - 0s 191us/step - loss: 2.9835 - acc: 0.1244\n",
      "Epoch 3/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.9051 - acc: 0.062 - ETA: 0s - loss: 2.8939 - acc: 0.118 - 0s 196us/step - loss: 2.9053 - acc: 0.1244\n",
      "Epoch 4/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.7878 - acc: 0.125 - ETA: 0s - loss: 2.8480 - acc: 0.102 - 0s 190us/step - loss: 2.8506 - acc: 0.1000\n",
      "Epoch 5/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.8244 - acc: 0.031 - ETA: 0s - loss: 2.6862 - acc: 0.153 - 0s 189us/step - loss: 2.7135 - acc: 0.1511\n",
      "Epoch 6/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.7217 - acc: 0.125 - ETA: 0s - loss: 2.6907 - acc: 0.112 - 0s 198us/step - loss: 2.6731 - acc: 0.1156\n",
      "Epoch 7/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.6148 - acc: 0.156 - ETA: 0s - loss: 2.7140 - acc: 0.088 - 0s 193us/step - loss: 2.7148 - acc: 0.0889\n",
      "Epoch 8/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.7032 - acc: 0.125 - ETA: 0s - loss: 2.7023 - acc: 0.122 - 0s 191us/step - loss: 2.6999 - acc: 0.1178\n",
      "Epoch 9/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.7970 - acc: 0.062 - ETA: 0s - loss: 2.6968 - acc: 0.096 - 0s 202us/step - loss: 2.6898 - acc: 0.0978\n",
      "Epoch 10/10\n",
      "450/450 [==============================] - ETA: 0s - loss: 2.8842 - acc: 0.062 - ETA: 0s - loss: 2.7522 - acc: 0.105 - 0s 191us/step - loss: 2.7180 - acc: 0.1111\n",
      "450/450 [==============================] - ETA: 10 - 1s 2ms/step\n",
      "['loss', 'acc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5545950253804524, 0.16]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "act = 'tanh'\n",
    "model.add(Dense(64, activation=act, input_dim=vectors.dim))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(48, activation=act))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(32, activation=act))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=10)\n",
    "score = model.evaluate(X, y)\n",
    "print(model.metrics_names)\n",
    "score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q1: What is the neural network learning?\n",
    "The neural network is trying to map summations of word2vec vectors (performed on sentences) one of the categories among 15 possible values.\n",
    "\n",
    "Q2: How does the depth or width of the network affect the training and the results?\n",
    "None of the changes I made to the network seem to have any effect. Adding regularization, changing the depth and width of the network, changing the activation function and the learning rate; none of these change the accuracy. It is always a value propogating between .15 and .16.\n",
    "\n",
    "Q2: What is regularization? Why is it important?\n",
    "It is to change the information in some way to prevent overfitting. The Dropout techinque randomly removes items from the data set as the network is trained. Since these removals will be different for each epoch, this also gives us a good mix of removals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: A6 Topic Modeling with MLPs\n",
      "OK, version v1.13.11\n",
      "=====================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR  | auth.py:91 | {'error': 'invalid_grant'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Open the following URL:\n",
      "\n",
      "https://okpy.org/client/login/\n",
      "\n",
      "After logging in, copy the code from the web page and paste it into the box.\n",
      "Then press the \"Enter\" key on your keyboard.\n",
      "\n",
      "Paste your code here: p7sC95YFuE5DJ566uydOmVbKdZ52VQ\n",
      "Successfully logged in as arjunshukla@u.boisestate.edu\n"
     ]
    }
   ],
   "source": [
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('a6.ok')\n",
    "ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving notebook... Saved 'A6-mlp-topic.ipynb'.\n",
      "Submit... 100% complete\n",
      "Submission successful for user: arjunshukla@u.boisestate.edu\n",
      "URL: https://okpy.org/boisestate/cs4-533/sp19/a6/submissions/0YDkxX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
