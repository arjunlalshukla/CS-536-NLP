{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to make sure you can import all of the libraries. Then move onto Part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import *\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from collections import Counter as ctr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, load the iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2]]), array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sklearn.datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['setosa', 'versicolor', 'virginica']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iris.target_names) # classes 0, 1, 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the iris data into a dataframe\n",
    "cols = ['f1', 'f2', 'f3', 'f4'] # we have four features to deal with\n",
    "data = pd.DataFrame(X,columns=cols)\n",
    "data['y'] = y # add the prediction label as a column\n",
    "# split into train/test data\n",
    "train, test = train_test_split(data, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate gaussian parameters for P(F|C)\n",
    "params_fc = {}\n",
    "for y_val in set(train.y):\n",
    "    sub_frame = train[train.y == y_val]\n",
    "    for f in cols:\n",
    "        params_fc['{}-{}'.format(y_val, f)] = (sub_frame[f].mean(), sub_frame[f].std())\n",
    "\n",
    "# estimate gaussian parameters for P(F)\n",
    "params_f = {}\n",
    "for f in cols:\n",
    "    params_f[f] = (train[f].mean(), train[f].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0-f1': (4.988461538461538, 0.35813620099277654),\n",
       "  '0-f2': (3.4384615384615387, 0.4079969833975964),\n",
       "  '0-f3': (1.473076923076923, 0.16384795954223488),\n",
       "  '0-f4': (0.27307692307692316, 0.11851647078003062),\n",
       "  '1-f1': (5.826923076923078, 0.4574343164282211),\n",
       "  '1-f2': (2.726923076923077, 0.316932412110459),\n",
       "  '1-f3': (4.2615384615384615, 0.4499572629278679),\n",
       "  '1-f4': (1.3230769230769233, 0.22504700363735983),\n",
       "  '2-f1': (6.591304347826085, 0.7134506694281741),\n",
       "  '2-f2': (2.986956521739131, 0.35330176108724926),\n",
       "  '2-f3': (5.534782608695653, 0.5629538134229405),\n",
       "  '2-f4': (2.0652173913043477, 0.24235341521342882)},\n",
       " {'f1': (5.770666666666668, 0.8311134396395896),\n",
       "  'f2': (3.053333333333334, 0.46711689992784267),\n",
       "  'f3': (3.685333333333333, 1.7524263745442201),\n",
       "  'f4': (1.1866666666666665, 0.7609264149765134)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the mean/std values for all the combinations\n",
    "params_fc, params_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gaussian(x, mu, sig):\n",
    "    return 1./(sqrt(2.*pi)*sig)*np.exp(-np.power((x - mu)/sig, 2.)/2)\n",
    "\n",
    "#P(F|C)\n",
    "def Pfc(feat='f1', F='',C=''):\n",
    "    mu,sigma = params_fc['{}-{}'.format(C,feat)]\n",
    "    return gaussian(F,mu,sigma)\n",
    "\n",
    "#P(F)\n",
    "def Pf(feat='f1', F=''):\n",
    "    mu,sigma=params_f[feat]\n",
    "    return gaussian(F,mu,sigma)\n",
    "\n",
    "#P(C) -- there are 50 of each type in the data, so each type is 50/150 -> 1/3\n",
    "def Pc(C=''):\n",
    "    return 1.0 / 3.0\n",
    "\n",
    "#P(C|F) = P(F|C) * P(C) / P(F)\n",
    "def Pcf(feat='f1', C='', F=''):\n",
    "    return Pfc(feat,F,C) * Pc(C) / Pf(feat,F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/casey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# call P(C|F) on all four individual features, multiply result together\n",
    "\n",
    "# note:  a \\ (i.e., a slash) at the end of a line in python means to continue the current line of code\n",
    "for y_val in set(test.y):\n",
    "    test[str(y_val)] = test.f1.map(lambda x: Pcf(feat='f1', C=y_val, F=x)) *\\\n",
    "    test.f2.map(lambda x: Pcf(feat='f2', C=y_val, F=x)) *\\\n",
    "    test.f3.map(lambda x: Pcf(feat='f3', C=y_val, F=x)) *\\\n",
    "    test.f4.map(lambda x: Pcf(feat='f4', C=y_val, F=x))\n",
    "    \n",
    "test['guess'] = test[['0','1','2']].idxmax(axis=1) # take the argmax class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[test.y.map(str) == test.guess]) / len(test) # see if the guess matches the actual class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check against the scikit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/casey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "Xtrain = pd.DataFrame.as_matrix(train[cols])\n",
    "ytrain = train.y\n",
    "Xtest  = pd.DataFrame.as_matrix(test[cols])\n",
    "ytest  = test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and instantiate classifier here\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(Xtrain, ytrain)\n",
    "preds = classifier.predict(Xtest)\n",
    "sklearn.metrics.accuracy_score(ytest, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
