{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as n\n",
    "from collections import Counter\n",
    "import itertools as i\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NBClassifier:\n",
    "    def __init__(self, train, types):\n",
    "        self.smooth = 0.00001\n",
    "        self.train = train\n",
    "        self.types = types\n",
    "        self.all_word_ctr = Counter([word for row in train for word in row])\n",
    "        self.all_type_ctr = Counter(types)\n",
    "        self.type_ctrs = {}\n",
    "        for _type in set(types):\n",
    "            type_rows = [train[i] for i in range(len(train)) if types[i] == _type]\n",
    "            type_words = [word for row in type_rows for word in row]\n",
    "            self.type_ctrs[_type] = Counter(type_words)\n",
    "        \n",
    "    def P_type(self, T=''):\n",
    "        return self.all_type_ctr[T] / len(self.train)\n",
    "\n",
    "    def P_word(self, W=''):\n",
    "        if W not in self.all_word_ctr:\n",
    "            return self.smooth\n",
    "        else:\n",
    "            return self.all_word_ctr[W] / len(self.train)\n",
    "        \n",
    "    def P_word_type(self, W='', T=''):\n",
    "        if W not in self.type_ctrs[T]:\n",
    "            return self.smooth\n",
    "        else:\n",
    "            return self.type_ctrs[T][W] / self.all_type_ctr[T]\n",
    "        \n",
    "    def P_type_word(self, W='', T=''):\n",
    "        return self.P_word_type(W, T) * self.P_type(T) / self.P_word(W)\n",
    "        \n",
    "    def P_type_sent(self, T='', S=''):\n",
    "        return np.prod([self.P_type_word(word, T) for word in S])\n",
    "    \n",
    "    def classify(self, sentence):\n",
    "        probs = [(_type, self.P_type_sent(_type, sentence)) for _type in set(self.types)]\n",
    "        return max(probs, key=lambda x: x[1])[0]\n",
    "    \n",
    "    def classify_all(self, test, types):\n",
    "        hyp = [self.classify(sentence) for sentence in test]\n",
    "        return accuracy_score(hyp, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('pnp-train.txt',delimiter='\\t',encoding='latin-1', names=['type','name'])\n",
    "train['clean'] = train.name.map(lambda x: x.lower().split())\n",
    "nbc = NBClassifier(list(train.clean), list(train.type))\n",
    "\n",
    "test = pd.read_csv('pnp-test.txt',delimiter='\\t',encoding='latin-1', names=['type','name'])\n",
    "test['clean'] = test.name.map(lambda x: x.lower().split())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q1) What is the accuracy of your classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy =  0.675047619048\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes accuracy = \", nbc.classify_all(list(test.clean), list(test.type)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q2) What is the random baseline for this task? What is the most common baseline for this task? Is the classifier working well when compared to these baselines?\n",
    "The classifier's accuracy of 67.5% is far beyond either of the 2 constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random baseline =  0.2\n",
      "most common baseline =  0.29817627732012764\n"
     ]
    }
   ],
   "source": [
    "print(\"random baseline = \", 1 / len(set(nbc.types)))\n",
    "print(\"most common baseline = \", nbc.all_type_ctr.most_common()[0][1] / len(nbc.train))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q3) What independence assumptions does your classifier make?\n",
    "The classifier assumes the order of the words is irrelevant, and only takes into account their occurrence, not their position."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q4) Identify three possible things you could try in order to improve your results.\n",
    "    1) Experiment with different smoothing values/methods.\n",
    "    2) Retain capitalization.\n",
    "    3) Try a different classification method, such as HMM."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q5) What constitutes \"training\" for this classifier? Is the classifier actually \"learning\" anything?\n",
    "The classifier is trained only by counting the occurrences of each word, and associating them with a type. The word is treated as independent from other words, so this is the only criterion."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q6) Why would changing your smoothing value change the results?\n",
    "The smoothing value is the default probability given to words that have never been seen. Changing this default value will make unseen words either less or more likely compared to other words, altering the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-4ec7f804fcfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'me.ok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'client'"
     ]
    }
   ],
   "source": [
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('me.ok')\n",
    "ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
